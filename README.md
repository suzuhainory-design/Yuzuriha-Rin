# Rie Kugimiya - 虚拟角色对话系统

一个基于大语言模型和深度学习的虚拟角色对话系统，通过训练BiLSTM序列标注模型模拟真人发消息的行为模式，包括分段、停顿、错别字、撤回重发等自然对话行为。

## ✨ 功能特点

### 已实现

- 🤖 **多LLM支持** - 支持OpenAI、Anthropic及自定义OpenAI兼容API
- 💬 **实时对话界面** - 流畅的Web聊天界面，支持打字动画
- ⚙️ **灵活配置** - 可自定义API密钥、模型、系统提示词等
- 💾 **本地存储** - 自动保存配置，无需重复输入

### 开发中

- 🧠 **消息行为建模** - BiLSTM-CRF序列标注模型，智能分段和停顿预测
- ✏️ **错别字注入** - 基于情绪的自然错别字模拟
- ↩️ **撤回重发** - 模拟真人发现错误后的撤回行为
- 📊 **情感分析** - 根据对话内容调整消息行为

## 🏗️ 系统架构

```bash
┌─────────────────┐
│   LLM Layer     │  生成对话内容
└────────┬────────┘
         │
┌────────▼────────┐
│ Behavior System │  消息行为建模 (核心贡献)
│  ├─ Segmenter   │  - BiLSTM-CRF分段 + 停顿预测
│  ├─ Typo        │  - 情绪感知的错别字注入
│  └─ Recall      │  - 撤回重发逻辑
└────────┬────────┘
         │
┌────────▼────────┐
│  Frontend UI    │  消息播放器 + 动画效果
└─────────────────┘
```

## 🛠️ 技术栈

**前端**

- 原生HTML + CSS + JavaScript
- 流畅的消息动画和打字效果

**后端**

- FastAPI - 现代化异步Web框架
- Pydantic - 数据验证和配置管理
- HTTPX - 异步HTTP客户端

**机器学习** (待实现)

- PyTorch - 深度学习框架
- BiLSTM-CRF - 序列标注模型
- LCCC数据集 - 中文对话数据
- Transformers - 模型加载和训练工具

## 📦 安装

### 环境要求

- Python 3.10+
- uv 包管理器
- (可选) CUDA 12.4+ 用于GPU加速

## 🚀 快速开始

### 1. 启动后端服务

```bash
# 方式1: 直接运行
python -m src.api.main

# 方式2: 使用uvicorn
uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000
```

### 2. 访问Web界面

打开浏览器访问 `http://localhost:8000`

### 3. 配置LLM

在配置面板中填入：

- **Provider**: 选择OpenAI/Anthropic/Custom
- **API Key**: 你的API密钥
- **Model**: 模型名称 (如 `gpt-3.5-turbo`)
- **System Prompt**: 角色设定提示词
- **Character Name**: 角色名称

### 4. 开始对话

保存配置后即可开始与虚拟角色聊天！

## 📁 项目结构

```bash
Rie_Kugimiya/
├── src/
│   ├── api/              # FastAPI后端
│   │   ├── main.py       # 应用入口
│   │   ├── routes.py     # API路由
│   │   ├── schemas.py    # Pydantic模型
│   │   └── llm_client.py # LLM客户端
│   ├── data/             # 数据处理模块 (待实现)
│   ├── models/           # ML模型定义 (待实现)
│   ├── behavior/         # 消息行为系统 (待实现)
│   └── utils/            # 工具函数
├── frontend/             # Web前端
│   ├── index.html
│   ├── chat.js
│   └── styles.css
├── data/                 # 数据存储
├── scripts/              # 训练脚本 (待实现)
├── tests/                # 单元测试
└── pyproject.toml        # 项目配置
```

## 🎯 开发路线图

### Phase 1: 基础对话系统 ✅

- [x] FastAPI后端框架
- [x] 多LLM API支持
- [x] Web聊天界面
- [x] 配置管理

### Phase 2: 数据处理 (进行中)

- [ ] LCCC数据集下载和预处理
- [ ] 训练数据生成（反向重建）
- [ ] 数据增强和验证

### Phase 3: 模型训练

- [ ] BiLSTM-CRF模型实现
- [ ] 分段点预测训练
- [ ] 停顿时长预测训练
- [ ] 模型评估和优化

### Phase 4: 行为系统

- [ ] 分段模块集成
- [ ] 错别字注入逻辑
- [ ] 撤回重发系统
- [ ] 前端播放器增强

### Phase 5: 优化和部署

- [ ] 端到端测试
- [ ] 性能优化
- [ ] 文档完善
- [ ] Demo准备

## 🔬 技术创新点

1. **语义感知的分段** - 不是简单的标点切分，而是理解上下文语义
2. **行为一致性** - 小模型保证相同输入产生一致的分段行为
3. **情绪驱动的停顿** - 停顿时长不仅依赖情绪，更依赖具体内容
4. **概率行为模型** - 错别字和撤回基于概率分布，更自然

## 📊 预期效果

| 指标 | 规则基线 | 模型方案 | 提升 |
|------|---------|---------|------|
| 分段合理性 | 68% | 84% | +23% |
| 停顿真实感 | 55% | 78% | +42% |
| 整体流畅度 | - | - | +23% |

## 🤝 贡献

这是一个课程项目，暂不接受外部贡献。

## 📄 许可证

MIT License

## 👨‍💻 作者

Leever - AI课程作业项目

---

**Note**: 本项目仍在积极开发中，消息行为建模系统（核心功能）正在实现。当前版本可用于基础的LLM对话交互。
